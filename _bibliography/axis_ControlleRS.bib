@book{gigi,
  author       = {Nathana{\"{e}}l Fijalkow and
  		  C. Aiswarya and
  		  Guy Avni and
                  Nathalie Bertrand and
                  Patricia Bouyer and
                  Romain Brenguier and
                  Arnaud Carayol and
                  Antonio Casares and
                  John Fearnley and
                  Hugo Gimbert and
                  Thomas A. Henzinger and
                  Paul Gastin and
                  Florian Horn and
                  Rasmus Ibsen{-}Jensen and
                  Nicolas Markey and
                  Benjamin Monmege and
                  Petr Novotn{\'{y}} and
                  Pierre Ohlmann and
                  Mickael Randour and
                  Ocan Sankur and
                  Sylvain Schmitz and
                  Olivier Serre and
                  Mateusz Skomra and
                  Nathalie Sznajder and
                  Pierre Vandenhove},
  title        = {Games on Graphs},
  publisher    = {Cambridge University Press},
  note         = {In press, Cambridge University Press},
  volume       = {abs/2305.10546},
  year         = {2025},
  url          = {https://doi.org/10.48550/arXiv.2305.10546},
  doi          = {10.48550/ARXIV.2305.10546},
  eprinttype    = {arXiv},
  eprint       = {2305.10546},
  arxiv        = {2305.10546},
  bibtex_show  = {true},
  abstract     = {The objective of this collaborative textbook is to present the state of the art on games on graphs, which is part of a larger research topic called game theory. Games on graphs is the field concerned with games whose rules and evolution are represented by a graph.},
  abbr         = {CUP}
}
@inproceedings{randourECCS,
year={2013},
isbn={978-3-319-00394-8},
booktitle={Proceedings of the European Conference on Complex Systems 2012, {ECCS} 2012, Brussels, Belgium, September 2-7, 2012},
series={Springer Proceedings in Complexity},
title={Automated {S}ynthesis of {R}eliable and {E}fficient {S}ystems {T}hrough {G}ame {T}heory: {A} {C}ase {S}tudy},
publisher={Springer},
author={Randour, Mickael},
  bibtex_show  = {true},
  abbr         = {ECCS},
  arxiv        = {1204.3283},
  abstract     = {Reactive computer systems bear inherent complexity due to continuous interactions with their environment. While this environment often proves to be uncontrollable, we still want to ensure that critical computer systems will not fail, no matter what they face. Examples are legion: railway traffic, power plants, plane navigation systems, etc. Formal verification of a system may ensure that it satisfies a given specification, but only applies to an already existing model of a system. In this work, we address the problem of synthesis: starting from a specification of the desired behavior, we show how to build a suitable system controller that will enforce this specification. In particular, we discuss recent developments of that approach for systems that must ensure Boolean behaviors (e.g., reachability, liveness) along with quantitative requirements over their execution (e.g., never drop out of fuel, ensure a suitable mean response time). We notably illustrate a powerful, practically useable algorithm for the automated synthesis of provably safe reactive systems.},
pages={731-738}
}

@book{Clarke2018,
  editor       = {Edmund M. Clarke and
                  Thomas A. Henzinger and
                  Helmut Veith and
                  Roderick Bloem},
  author       = {Edmund M. Clarke and
                  Thomas A. Henzinger and
                  Helmut Veith and
                  Roderick Bloem},
  title        = {Handbook of Model Checking},
  publisher    = {Springer},
  year         = {2018},
  url          = {https://doi.org/10.1007/978-3-319-10575-8},
  doi          = {10.1007/978-3-319-10575-8},
  isbn         = {978-3-319-10574-1},
  timestamp    = {Mon, 03 Jan 2022 22:13:30 +0100},
  biburl       = {https://dblp.org/rec/reference/mc/2018.bib},
  abbr         = {Book},
  pdf          = {https://link.springer.com/book/10.1007/978-3-319-10575-8},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{cocktail,
  author       = {James C. A. Main and
                  Mickael Randour},
  title        = {Mixing Any Cocktail with Limited Ingredients: On the Structure of
                  Payoff Sets in Multi-Objective MDPs and its Impact on Randomised Strategies},
  journal      = {CoRR},
  arxiv        = {2502.18296},
  volume       = {abs/2502.18296},
  year         = {2025},
  bibtex_show  = {true},
  abbr         = {arXiv},
  award        = {Unpublished work.},
  award_name   = {Preprint},
  abstract     = {We consider multi-dimensional payoff functions in Markov decision processes, and ask whether a given expected payoff vector can be achieved or not. In general, pure strategies (i.e., not resorting to randomisation) do not suffice for this problem.
We study the structure of the set of expected payoff vectors of all strategies given a multi-dimensional payoff function and its consequences regarding randomisation requirements for strategies. In particular, we prove that for any payoff for which the expectation is well-defined under all strategies, it is sufficient to mix (i.e., randomly select a pure strategy at the start of a play and committing to it for the rest of the play) finitely many pure strategies to approximate any expected payoff vector up to any precision. Furthermore, for any payoff for which the expected payoff is finite under all strategies, any expected payoff can be obtained exactly by mixing finitely many strategies.}
}
@article{chunck,
  author       = {Michal Ajdarów and James C. A. Main and Petr Novotný and Mickael Randour},
  title        = {Taming Infinity one Chunk at a Time: Concisely Represented Strategies in One-Counter MDPs},
  journal      = {CoRR},
  arxiv        = {2503.00788},
  volume       = {abs/2503.00788},
  year         = {2025},
  bibtex_show  = {true},
  abbr         = {arXiv},
  award        = {Unpublished work.},
  award_name   = {Preprint},
  abstract     = {Markov decision processes (MDPs) are a canonical model to reason about decision making within a stochastic environment. We study a fundamental class of infinite MDPs: one-counter MDPs (OC-MDPs). They extend finite MDPs via an associated counter taking natural values, thus inducing an infinite MDP over the set of configurations (current state and counter value). We consider two characteristic objectives: reaching a target state (state-reachability), and reaching a target state with counter value zero (selective termination). The synthesis problem for the latter is not known to be decidable and connected to major open problems in number theory. Furthermore, even seemingly simple strategies (e.g., memoryless ones) in OC-MDPs might be impossible to build in practice (due to the underlying infinite configuration space): we need finite, and preferably small, representations.
To overcome these obstacles, we introduce two natural classes of concisely represented strategies based on a (possibly infinite) partition of counter values in intervals. For both classes, and both objectives, we study the verification problem (does a given strategy ensure a high enough probability for the objective?), and two synthesis problems (does there exist such a strategy?): one where the interval partition is fixed as input, and one where it is only parameterized. We develop a generic approach based on a compression of the induced infinite MDP that yields decidability in all cases, with all complexities within PSPACE. }
}
