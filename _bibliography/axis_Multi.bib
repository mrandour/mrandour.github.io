@book{DBLP:journals/corr/abs-2305-10546,
  author       = {Nathana{\"{e}}l Fijalkow and
                  Nathalie Bertrand and
                  Patricia Bouyer{-}Decitre and
                  Romain Brenguier and
                  Arnaud Carayol and
                  John Fearnley and
                  Hugo Gimbert and
                  Florian Horn and
                  Rasmus Ibsen{-}Jensen and
                  Nicolas Markey and
                  Benjamin Monmege and
                  Petr Novotn{\'{y}} and
                  Mickael Randour and
                  Ocan Sankur and
                  Sylvain Schmitz and
                  Olivier Serre and
                  Mateusz Skomra},
  title        = {Games on Graphs},
  journal      = {CoRR},
  volume       = {abs/2305.10546},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.10546},
  doi          = {10.48550/ARXIV.2305.10546},
  eprinttype    = {arXiv},
  eprint       = {2305.10546},
  timestamp    = {Thu, 25 May 2023 01:00:00 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2305-10546.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  arxiv        = {2305.10546},
  bibtex_show  = {true},
  abstract     = {The objective of this collaborative textbook is to present the state of the art on games on graphs, which is part of a larger research topic called game theory. Games on graphs is the field concerned with games whose rules and evolution are represented by a graph.},
  abbr         = {Book}
}
@article{DBLP:journals/iandc/BruyereFRR17,
  author       = {Véronique Bruyère and
                  Emmanuel Filiot and
                  Mickael Randour and
                  Jean{-}Fran{\c{c}}ois Raskin},
  title        = {Meet your expectations with guarantees: Beyond worst-case synthesis
                  in quantitative games},
  journal      = {Information and Computation},
  volume       = {254},
  pages        = {259--295},
  year         = {2017},
  url          = {https://doi.org/10.1016/j.ic.2016.10.011},
  doi          = {10.1016/J.IC.2016.10.011},
  timestamp    = {Sat, 05 Sep 2020 01:00:00 +0200},
  biburl       = {https://dblp.org/rec/journals/iandc/BruyereFRR17.bib},
  bibtex_show  = {true},
  abbr         = {Inf. Comput.},
  arxiv        = {1309.5439},
  abstract     = {We extend the quantitative synthesis framework by going beyond the worst-case. On the one hand, classical analysis of two-player games involves an adversary (modeling the environment of the system) which is purely antagonistic and asks for strict guarantees. On the other hand, stochastic models like Markov decision processes represent situations where the system is faced to a purely randomized environment: the aim is then to optimize the expected payoff, with no guarantee on individual outcomes. We introduce the beyond worst-case synthesis problem, which is to construct strategies that guarantee some quantitative requirement in the worst-case while providing an higher expected value against a particular stochastic model of the environment given as input. This problem is relevant to produce system controllers that provide nice expected performance in the everyday situation while ensuring a strict (but relaxed) performance threshold even in the event of very bad (while unlikely) circumstances. We study the beyond worst-case synthesis problem for two important quantitative settings: the mean-payoff and the shortest path. In both cases, we show how to decide the existence of finite-memory strategies satisfying the problem and how to synthesize one if one exists. We establish algorithms and we study complexity bounds and memory requirements.},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/lmcs/BrihayeDOR20,
  author       = {Thomas Brihaye and
                  Florent Delgrange and
                  Youssouf Oualhadj and
                  Mickael Randour},
  title        = {Life is Random, Time is Not: Markov Decision Processes with Window
                  Objectives},
  journal      = {Logical Methods in Computer Science},
  volume       = {16},
  number       = {4},
  year         = {2020},
  url          = {https://lmcs.episciences.org/6975},
  timestamp    = {Wed, 16 Dec 2020 00:00:00 +0100},
  biburl       = {https://dblp.org/rec/journals/lmcs/BrihayeDOR20.bib},
  bibtex_show  = {true},
  abbr         = {LMCS},
  arxiv        = {1901.03571},
  abstract     = {The window mechanism was introduced by Chatterjee et al. to strengthen classical game objectives with time bounds. It permits to synthesize system controllers that exhibit acceptable behaviors within a configurable time frame, all along their infinite execution, in contrast to the traditional objectives that only require correctness of behaviors in the limit. The window concept has proved its interest in a variety of two-player zero-sum games because it enables reasoning about such time bounds in system specifications, but also thanks to the increased tractability that it usually yields. In this work, we extend the window framework to stochastic environments by considering Markov decision processes. A fundamental problem in this context is the threshold probability problem: given an objective it aims to synthesize strategies that guarantee satisfying runs with a given probability. We solve it for the usual variants of window objectives, where either the time frame is set as a parameter, or we ask if such a time frame exists. We develop a generic approach for window-based objectives and instantiate it for the classical mean-payoff and parity objectives, already considered in games. Our work paves the way to a wide use of the window mechanism in stochastic models.},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/fmsd/RandourRS17,
  author       = {Mickael Randour and
                  Jean{-}Fran{\c{c}}ois Raskin and
                  Ocan Sankur},
  title        = {Percentile queries in multi-dimensional Markov decision processes},
  journal      = {Formal Methods in System Design},
  volume       = {50},
  number       = {2-3},
  pages        = {207--248},
  year         = {2017},
  url          = {https://doi.org/10.1007/s10703-016-0262-7},
  doi          = {10.1007/S10703-016-0262-7},
  timestamp    = {Fri, 13 Mar 2020 00:00:00 +0100},
  biburl       = {https://dblp.org/rec/journals/fmsd/RandourRS17.bib},
  bibtex_show  = {true},
  abbr         = {FMSD},
  arxiv        = {1410.4801},
  abstract     = {Markov decision processes (MDPs) with multi-dimensional weights are useful to analyze systems with multiple objectives that may be conflicting and require the analysis of trade-offs. We study the complexity of percentile queries in such MDPs and give algorithms to synthesize strategies that enforce such constraints. Given a multi-dimensional weighted MDP and a quantitative payoff function f, thresholds v_i (one per dimension), and probability thresholds α_i, we show how to compute a single strategy to enforce that for all dimensions i, the probability of outcomes ρ satisfying f_i(ρ)≥v_i is at least α_i. We consider classical quantitative payoffs from the literature (sup, inf, lim sup, lim inf, mean-payoff, truncated sum, discounted sum). Our work extends to the quantitative case the multi-objective model checking problem studied by Etessami et al. in unweighted MDPs.},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

