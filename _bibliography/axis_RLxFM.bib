@inproceedings{DBLP:conf/aaai/BrazdilC0V20,
  author       = {Tom{\'{a}}s Br{\'{a}}zdil and
                  Krishnendu Chatterjee and
                  Petr Novotn{\'{y}} and
                  Jiri Vahala},
  title        = {Reinforcement Learning of Risk-Constrained Policies in Markov Decision
                  Processes},
  booktitle    = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2020, The Thirty-Second Innovative Applications of Artificial Intelligence
                  Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
                  Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
                  February 7-12, 2020},
  pages        = {9794--9801},
  publisher    = {{AAAI} Press},
  year         = {2020},
  abbr         = {AAAI},
  pdf          = {https://ojs.aaai.org/index.php/AAAI/article/view/6531},
  url          = {https://doi.org/10.1609/aaai.v34i06.6531},
  doi          = {10.1609/AAAI.V34I06.6531},
  timestamp    = {Sat, 21 Oct 2023 10:46:19 +0200},
  biburl       = {https://dblp.org/rec/conf/aaai/BrazdilC0V20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/fmsd/RandourRS17,
  author       = {Mickael Randour and
                  Jean{-}Fran{\c{c}}ois Raskin and
                  Ocan Sankur},
  title        = {Percentile queries in multi-dimensional Markov decision processes},
  journal      = {Formal Methods in System Design},
  volume       = {50},
  number       = {2-3},
  pages        = {207--248},
  year         = {2017},
  url          = {https://doi.org/10.1007/s10703-016-0262-7},
  doi          = {10.1007/S10703-016-0262-7},
  timestamp    = {Fri, 13 Mar 2020 00:00:00 +0100},
  biburl       = {https://dblp.org/rec/journals/fmsd/RandourRS17.bib},
  bibtex_show  = {true},
  abbr         = {FMSD},
  arxiv        = {1410.4801},
  abstract     = {Markov decision processes (MDPs) with multi-dimensional weights are useful to analyze systems with multiple objectives that may be conflicting and require the analysis of trade-offs. We study the complexity of percentile queries in such MDPs and give algorithms to synthesize strategies that enforce such constraints. Given a multi-dimensional weighted MDP and a quantitative payoff function f, thresholds v_i (one per dimension), and probability thresholds α_i, we show how to compute a single strategy to enforce that for all dimensions i, the probability of outcomes ρ satisfying f_i(ρ)≥v_i is at least α_i. We consider classical quantitative payoffs from the literature (sup, inf, lim sup, lim inf, mean-payoff, truncated sum, discounted sum). Our work extends to the quantitative case the multi-objective model checking problem studied by Etessami et al. in unweighted MDPs.},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
